<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Why Australia should move to regulate Big Tech</title>
</head>
<body class="blog-body">
{{ template "app.html" }}
<h2 class="monospace-text"><u>Why Australia should move to regulate Big Tech</u></h2>
<p class="blog">
<br>
Big technology companies like Facebook and Google make millions of dollars a year from Australian consumers and advertisers. Their platforms also subtly promote harmful content including misinformation, political extremism, and scams. The main issue that seems not to be understood by the Australian Government, is that this is by design. Artificial Intelligence systems designed to optimise for time on site promote this kind of content, which leads people to share, react, and engage, further spreading negativity. This problem has created a few disparate political camps that can largely be summarised by the following philosophies.
<br>
<br>
<b>1) pro-regulation.</b>
<br>
<br>
This group believes that we need to regulate social media, as it promotes harmful content, and that harmful content spreads faster than neutral content. They argue this incentivises people and news organisations to post and produce content in a certain kind of style that is corrosive to civil discource and the social fabric.
<br>
<br>
<b>2) free speech free market neoliberalism.</b>
<br>
<br>
This group argues that social media companies have the freedom to innovate, and that to place restrictions on what content these platforms can promote is an infringement on freedom of speech.
<br>
<br>
<i>Associations: Silicon Valley, Venture Capital, Technological Utopianism, Neoliberalism, Wall Street.</i>
<br><br>
<b>3) anti-rationalist cancel culture.</b>
<br><br>
This group believes that certain people or groups on social media need to be cancelled or banned, treated as political outcasts because of their views. This is largely a reaction to negative content that has been promoted for profit. There does not appear to be widespread insight into the fact that negative reactions to disagreeable content effectively promotes that content in the social media sphere, and creates advertising revenue for big tech.
<br><br>
<i>Associations: Far Left, Wokeism.</i>
<br><br>
<b>4) populist anti-elitism.</b> 
<br><br>
This group argues that that the mainstream media are liberal elites who control public information and tell everyday people what to think. This group is typically associated with right wing ideologies and shares _some_ similarities to the free speech free markets group. The prevailing sentiment is that the traditional, mainstream media, manipulate news and are corrupt. This is typically associated with a distrust of institutions and an openness to conspiracy theories. 
<br><br>
<i>Associations: Far Right, Breitbart, Trump, Brexit, Populism.</i>
<br><br>
Although many of those in groups 3 and 4 lack insight into how social media algorithms operate, many influencers and media outlets on all sides of the political spectrum understand that controversal content is more likely to go viral, and exploit this fact for their own commercial gain. In that sense it could be argued that they belong more in group 2.
<br><br>
The algorithms and AI that social media companies use to keep people engaged and addicted to online media are not regulated by governments. People focus more on the content as the problem, and seem to forget about the algorithm that is driving the content and the engagement. This is actually an age old problem of media, which Marshal McLuhan recognised when he famously said "the medium is the message". The medium in which content is presented, is actually more powerful and more influential to the viewer, than the content itself.
<br><br>
People are focused on the content of the medium, not the medium itself. The medium is driven by AI, it can be thought of as a combination of the user's temperament and the AI driving the choice of promoted content. The AI and algorithms promote and sort through different content to  maximise time on site and engagement of the end user. The government and general public tend to forget this, and focus on the content itself as the problem. The far [right] [left] extremist posts, the polarising news article, sensationalist headline or video title. In forgetting that the medium is the message, we attempt to treat the symptoms of the problem not the cause, and instead create organisations to prevent misinformation, and hire more police to prevent outbreaks of public violence, for example. This is expensive and ultimately unsustainable because, in the long run, the technology will continue to advance in sophistication.
<br><br> 
Social media companies and technology companies that use AI need to be regulated, just like many other industries are regulated. The technology is only going to increase in sophistication, the AI will get more nuanced and predictive in its recommendations. The debate at the moment around regulation is not a mature one. People focus more on the political in-fighting on social media, rather than thinking about the medium itself and the psychological manipulation that occurs on behalf of social media giants through the technology. The focus is more on the message, and people forget about the medium, which leads to a kind of collective hypnosis.</p>
<br>
<b>Lachie</b>
<br>
<br>
<p class="monospace-text">Written August 2024</p>
</body>
</html>
